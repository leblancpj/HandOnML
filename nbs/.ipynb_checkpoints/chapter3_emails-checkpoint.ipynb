{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3, Exercise : Email Spam / Ham Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple email classification system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Frame the problem and look at the big picture\n",
    "2. Get the data\n",
    "3. Explore the data to gain insights\n",
    "4. Prepare the data to better expose the underlying data patterns to ML-Learning algorithms\n",
    "5. Explore many different models and short-list the best ones\n",
    "6. Fine-tune your models and combine them into a great solution\n",
    "7. Present your solution (skip for this exercise)\n",
    "8. Launch, monitor, and maitain your system (skip for this exercise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is a bunch of text email files in folders called spam and ham.  Spam are bad, ham = not spam (i.e. legit). Since they are basically text, most of the work will be in creating a feature dataframe / matrix.  This will involve some sort of text feature extraction.  Perhaps Tfidf or something similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# required imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../datasets/emails/\"\n",
    "SPAM_FOLDER = DATA_FOLDER + \"spam/\"\n",
    "HAM_FOLDER = DATA_FOLDER + \"ham/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_filenames = os.listdir(SPAM_FOLDER)\n",
    "ham_filenames = os.listdir(HAM_FOLDER)\n",
    "#for filename in os.listdir('SPAM_FOLDER'):   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From exmh-workers-admin@redhat.com  Thu Aug 22 12:36:23 2002\n",
      "Return-Path: <exmh-workers-admin@spamassassin.taint.org>\n",
      "Delivered-To: zzzz@localhost.netnoteinc.com\n",
      "Received: from localhost (localhost [127.0.0.1])\n",
      "\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id D03E543C36\n",
      "\tfor <zzzz@localhost>; Thu, 22 Aug 2002 07:36:16 -0400 (EDT)\n",
      "Received: from phobos [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 12:36:16 +0100 (IST)\n",
      "Received: from listman.spamassassin.taint.org (listman.spamassassin.taint.org [66.187.233.211]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g7MBYrZ04811 for\n",
      "    <zzzz-exmh@spamassassin.taint.org>; Thu, 22 Aug 2002 12:34:53 +0100\n",
      "Received: from listman.spamassassin.taint.org (localhost.localdomain [127.0.0.1]) by\n",
      "    listman.redhat.com (Postfix) with ESMTP id 8386540858; Thu, 22 Aug 2002\n",
      "    07:35:02 -0400 (EDT)\n",
      "Delivered-To: exmh-workers@listman.spamassassin.taint.org\n",
      "Received: from int-mx1.corp.spamassassin.taint.org (int-mx1.corp.spamassassin.taint.org\n",
      "    [172.16.52.254]) by listman.redhat.com (Postfix) with ESMTP id 10CF8406D7\n",
      "    for <exmh-workers@listman.redhat.com>; Thu, 22 Aug 2002 07:34:10 -0400\n",
      "    (EDT)\n",
      "Received: (from mail@localhost) by int-mx1.corp.spamassassin.taint.org (8.11.6/8.11.6)\n",
      "    id g7MBY7g11259 for exmh-workers@listman.redhat.com; Thu, 22 Aug 2002\n",
      "    07:34:07 -0400\n",
      "Received: from mx1.spamassassin.taint.org (mx1.spamassassin.taint.org [172.16.48.31]) by\n",
      "    int-mx1.corp.redhat.com (8.11.6/8.11.6) with SMTP id g7MBY7Y11255 for\n",
      "    <exmh-workers@redhat.com>; Thu, 22 Aug 2002 07:34:07 -0400\n",
      "Received: from ratree.psu.ac.th ([202.28.97.6]) by mx1.spamassassin.taint.org\n",
      "    (8.11.6/8.11.6) with SMTP id g7MBIhl25223 for <exmh-workers@redhat.com>;\n",
      "    Thu, 22 Aug 2002 07:18:55 -0400\n",
      "Received: from delta.cs.mu.OZ.AU (delta.coe.psu.ac.th [172.30.0.98]) by\n",
      "    ratree.psu.ac.th (8.11.6/8.11.6) with ESMTP id g7MBWel29762;\n",
      "    Thu, 22 Aug 2002 18:32:40 +0700 (ICT)\n",
      "Received: from munnari.OZ.AU (localhost [127.0.0.1]) by delta.cs.mu.OZ.AU\n",
      "    (8.11.6/8.11.6) with ESMTP id g7MBQPW13260; Thu, 22 Aug 2002 18:26:25\n",
      "    +0700 (ICT)\n",
      "From: Robert Elz <kre@munnari.OZ.AU>\n",
      "To: Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n",
      "Cc: exmh-workers@spamassassin.taint.org\n",
      "Subject: Re: New Sequences Window\n",
      "In-Reply-To: <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
      "References: <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
      "    <1029882468.3116.TMDA@deepeddy.vircio.com> <9627.1029933001@munnari.OZ.AU>\n",
      "    <1029943066.26919.TMDA@deepeddy.vircio.com>\n",
      "    <1029944441.398.TMDA@deepeddy.vircio.com>\n",
      "MIME-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Message-Id: <13258.1030015585@munnari.OZ.AU>\n",
      "X-Loop: exmh-workers@spamassassin.taint.org\n",
      "Sender: exmh-workers-admin@spamassassin.taint.org\n",
      "Errors-To: exmh-workers-admin@spamassassin.taint.org\n",
      "X-Beenthere: exmh-workers@spamassassin.taint.org\n",
      "X-Mailman-Version: 2.0.1\n",
      "Precedence: bulk\n",
      "List-Help: <mailto:exmh-workers-request@spamassassin.taint.org?subject=help>\n",
      "List-Post: <mailto:exmh-workers@spamassassin.taint.org>\n",
      "List-Subscribe: <https://listman.spamassassin.taint.org/mailman/listinfo/exmh-workers>,\n",
      "    <mailto:exmh-workers-request@redhat.com?subject=subscribe>\n",
      "List-Id: Discussion list for EXMH developers <exmh-workers.spamassassin.taint.org>\n",
      "List-Unsubscribe: <https://listman.spamassassin.taint.org/mailman/listinfo/exmh-workers>,\n",
      "    <mailto:exmh-workers-request@redhat.com?subject=unsubscribe>\n",
      "List-Archive: <https://listman.spamassassin.taint.org/mailman/private/exmh-workers/>\n",
      "Date: Thu, 22 Aug 2002 18:26:25 +0700\n",
      "\n",
      "    Date:        Wed, 21 Aug 2002 10:54:46 -0500\n",
      "    From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n",
      "    Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
      "\n",
      "\n",
      "  | I can't reproduce this error.\n",
      "\n",
      "For me it is very repeatable... (like every time, without fail).\n",
      "\n",
      "This is the debug log of the pick happening ...\n",
      "\n",
      "18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\n",
      "18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\n",
      "18:19:04 Ftoc_PickMsgs {{1 hit}}\n",
      "18:19:04 Marking 1 hits\n",
      "18:19:04 tkerror: syntax error in expression \"int ...\n",
      "\n",
      "Note, if I run the pick command by hand ...\n",
      "\n",
      "delta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\n",
      "1 hit\n",
      "\n",
      "That's where the \"1 hit\" comes from (obviously).  The version of nmh I'm\n",
      "using is ...\n",
      "\n",
      "delta$ pick -version\n",
      "pick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\n",
      "\n",
      "And the relevant part of my .mh_profile ...\n",
      "\n",
      "delta$ mhparam pick\n",
      "-seq sel -list\n",
      "\n",
      "\n",
      "Since the pick command works, the sequence (actually, both of them, the\n",
      "one that's explicit on the command line, from the search popup, and the\n",
      "one that comes from .mh_profile) do get created.\n",
      "\n",
      "kre\n",
      "\n",
      "ps: this is still using the version of the code form a day ago, I haven't\n",
      "been able to reach the cvs repository today (local routing issue I think).\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________\n",
      "Exmh-workers mailing list\n",
      "Exmh-workers@redhat.com\n",
      "https://listman.redhat.com/mailman/listinfo/exmh-workers\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read contents of all SPAM and HAM files\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "spam_corpus = []\n",
    "ham_corpus = []\n",
    "\n",
    "contents = \"\"\n",
    "# SPAM\n",
    "for spam_file in spam_filenames:\n",
    "    with open(SPAM_FOLDER + spam_file, \"r\", errors='ignore') as f:\n",
    "        contents = f.read()\n",
    "        #spam_corpus.append(TAG_RE.sub('', contents))\n",
    "        spam_corpus.append(contents)\n",
    "spam_target = np.ones(len(spam_corpus))\n",
    "#print(spam_target[0:10])\n",
    "\n",
    "contents = \"\"\n",
    "# HAM\n",
    "for ham_file in ham_filenames:\n",
    "    with open(HAM_FOLDER + ham_file, \"r\", errors='ignore') as f:\n",
    "        contents = f.read()\n",
    "        #ham_corpus.append(TAG_RE.sub('', contents))\n",
    "        ham_corpus.append(contents)\n",
    "ham_target = np.zeros(len(ham_corpus))\n",
    "\n",
    "# Combine Spam / Ham Corpus\n",
    "corpus = []\n",
    "corpus.extend(spam_corpus)\n",
    "corpus.extend(ham_corpus)\n",
    "print(ham_corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data to gain insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "# first play around with vectorizers\n",
    "vectorizer = CountVectorizer(stop_words='english', max_df=1.0, min_df=3)\n",
    "print(vectorizer)\n",
    "fit = vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1898, 22277)\n",
      "[[ 0  0  0 ...,  0  0  0]\n",
      " [ 1  0  1 ...,  0  0  0]\n",
      " [ 2  8  0 ...,  0  0  0]\n",
      " ..., \n",
      " [70  0  0 ...,  0  0  0]\n",
      " [ 0  0  4 ...,  0  0  0]\n",
      " [ 0  0  0 ...,  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# transform spam\n",
    "X_spam = fit.transform(spam_corpus)\n",
    "print(X_spam.shape)\n",
    "print(X_spam.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2501, 22277)\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 5 ..., 0 0 0]\n",
      " [2 0 5 ..., 0 0 0]\n",
      " ..., \n",
      " [3 0 4 ..., 0 0 0]\n",
      " [1 0 7 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# transform ham\n",
    "X_ham = fit.transform(ham_corpus)\n",
    "print(X_ham.shape)\n",
    "print(X_ham.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x0  x1  x2  x3  x4  x5  x6  x7  x8  x9  ...   x22268  x22269  x22270  \\\n",
      "0   0   0   0   0   0   0   0   0   0   0  ...        0       0       0   \n",
      "1   1   0   1   0   1   0   0   0   0   0  ...        0       0       0   \n",
      "2   2   8   0   0   0   0   0   0   0   0  ...        0       0       0   \n",
      "3   1   0   1   0   0   0   0   0   0   0  ...        0       0       0   \n",
      "4   1   0   1   0   0   0   0   0   0   0  ...        0       0       0   \n",
      "\n",
      "   x22271  x22272  x22273  x22274  x22275  x22276  Spam  \n",
      "0       0       0       0       0       0       0   1.0  \n",
      "1       0       0       0       0       0       0   1.0  \n",
      "2       0       0       0       0       0       0   1.0  \n",
      "3       0       0       0       0       0       0   1.0  \n",
      "4       0       0       0       0       0       0   1.0  \n",
      "\n",
      "[5 rows x 22278 columns]\n"
     ]
    }
   ],
   "source": [
    "# combine features and targets\n",
    "# HAM\n",
    "ham = pd.DataFrame(data=X_ham.toarray(), columns=['x'+str(i) for i in range(X_ham.shape[1])])\n",
    "ham = ham.assign(Spam = pd.Series(ham_target, index=ham.index))\n",
    "\n",
    "# SPAM\n",
    "spam = pd.DataFrame(data=X_spam.toarray(), columns=['x'+str(i) for i in range(X_spam.shape[1])])\n",
    "spam = spam.assign(Spam = pd.Series(spam_target, index=spam.index))\n",
    "\n",
    "# Combine them\n",
    "train = pd.concat([spam, ham], ignore_index=True)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x22268</th>\n",
       "      <th>x22269</th>\n",
       "      <th>x22270</th>\n",
       "      <th>x22271</th>\n",
       "      <th>x22272</th>\n",
       "      <th>x22273</th>\n",
       "      <th>x22274</th>\n",
       "      <th>x22275</th>\n",
       "      <th>x22276</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x0  x1  x2  x3  x4  x5  x6  x7  x8  x9  ...   x22268  x22269  x22270  \\\n",
       "0   1   0   0   0   0   0   0   0   0   0  ...        0       0       0   \n",
       "1   0   0   2   0   0   0   0   0   0   0  ...        0       0       0   \n",
       "2   0   0   0   0   0   0   0   0   0   0  ...        0       0       0   \n",
       "3   3   0   5   0   0   0   0   0   0   0  ...        0       0       0   \n",
       "4   0   0   0   0   0   0   0   0   0   0  ...        0       0       0   \n",
       "\n",
       "   x22271  x22272  x22273  x22274  x22275  x22276  Spam  \n",
       "0       0       0       0       0       0       0   0.0  \n",
       "1       0       0       0       0       0       0   0.0  \n",
       "2       0       0       0       0       0       0   1.0  \n",
       "3       0       0       0       0       0       0   0.0  \n",
       "4       0       0       0       0       0       0   1.0  \n",
       "\n",
       "[5 rows x 22278 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to reindex and shuffle?\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x22267</th>\n",
       "      <th>x22268</th>\n",
       "      <th>x22269</th>\n",
       "      <th>x22270</th>\n",
       "      <th>x22271</th>\n",
       "      <th>x22272</th>\n",
       "      <th>x22273</th>\n",
       "      <th>x22274</th>\n",
       "      <th>x22275</th>\n",
       "      <th>x22276</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x0  x1  x2  x3  x4  x5  x6  x7  x8  x9   ...    x22267  x22268  x22269  \\\n",
       "0   1   0   0   0   0   0   0   0   0   0   ...         0       0       0   \n",
       "\n",
       "   x22270  x22271  x22272  x22273  x22274  x22275  x22276  \n",
       "0       0       0       0       0       0       0       0  \n",
       "\n",
       "[1 rows x 22277 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[:1,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore several models to create a short list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a simple SGD classifier?\n",
    "clf = SGDClassifier()\n",
    "clf.fit(train.iloc[:,:-1], train.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune your models and combine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Present solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
